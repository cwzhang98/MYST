{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-20T15:04:47.268055Z",
     "start_time": "2024-03-20T15:04:44.601823Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/cwzhang98/anaconda3/envs/st/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fairseq.logging import progress_bar\n",
    "from fairseq import options, tasks, utils\n",
    "from argparse import Namespace\n",
    "from fairseq.dataclass.utils import convert_namespace_to_omegaconf\n",
    "from fairseq.models.speech_to_text.s2t_transformer_with_cif_contrast import S2TTransformerWithCifContrast as model\n",
    "from fairseq.models.speech_to_text.s2t_transformer_with_cif_contrast import S2TTransformerWithCifContrastConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:53:21 | INFO | fairseq.tasks.speech_to_text_cif_muti_contrast | joint dict size: 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4000000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4000000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'tst-COMMON_st', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'speech_to_text_cif_muti_contrast', 'data': '/home2/cwzhang98/dataset/mustc', 'use_joint_dict': True, 'config_yaml': '/home2/cwzhang98/dataset/mustc/en-de/config_st.yaml', 'max_audio_tokens': 1000000, 'max_text_tokens': 4000, 'max_audio_positions': 1000000, 'max_source_positions': 4000000, 'max_target_positions': 1024, 'lang_pairs': 'en-de', 'lang_prefix_tok': '<lang:de>', 'external_mt_data': None, 'text_data_sample_ratio': 1.0, 'eval_bleu': True, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': False, 'eval_bleu_bpe': None, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': True, 'seed': 1, 'rebuild_batches': True}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n"
     ]
    }
   ],
   "source": [
    "parser = options.get_generation_parser()\n",
    "cfg = options.parse_args_and_arch(parser, input_args=[\n",
    "    '/home2/cwzhang98/dataset/mustc',\n",
    "    '--gen-subset', 'tst-COMMON_st',\n",
    "    '--task', 'speech_to_text_cif_muti_contrast',\n",
    "    '--max-tokens', '4000000',\n",
    "    '--max-source-positions', '4000000',\n",
    "    '--config-yaml', '/home2/cwzhang98/dataset/mustc/en-de/config_st.yaml',\n",
    "    '--use-joint-dict'\n",
    "])\n",
    "if isinstance(cfg, Namespace):\n",
    "    cfg = convert_namespace_to_omegaconf(cfg)\n",
    "print(cfg)\n",
    "task = tasks.setup_task(cfg.task)\n",
    "tgt_dict = task.target_dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:53:41.366599Z",
     "start_time": "2024-02-26T12:53:39.701288Z"
    }
   },
   "id": "cd087d6b01dc0a3"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:53:21 | INFO | fairseq.tasks.speech_to_text_cif_muti_contrast | pre-tokenizer: {'tokenizer': None}\n",
      "2024-02-26 12:53:21 | INFO | fairseq.tasks.speech_to_text_cif_muti_contrast | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/home2/cwzhang98/dataset/mustc/en-de/spm_unigram_10000_st.model'}\n",
      "2024-02-26 12:53:22 | INFO | fairseq.data.audio.speech_to_text_dataset | 'tst-COMMON_st' has 0.00% OOV\n",
      "2024-02-26 12:53:22 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechTextTripleDataset(split=\"tst-COMMON_st\", n_samples=2_587, prepend_tgt_lang_tag=True, n_frames_per_step=1, shuffle=False, feature_transforms=None, waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "task.load_dataset(cfg.dataset.gen_subset)\n",
    "ckpt_path = '/home2/cwzhang98/project/MYST/checkpoint/_checkpoint46.pt'\n",
    "ckpt = torch.load(ckpt_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:53:43.423414Z",
     "start_time": "2024-02-26T12:53:41.366755Z"
    }
   },
   "id": "23325a4f544a28bf"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1915b45a674396"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args = S2TTransformerWithCifContrastConfig(**ckpt['cfg']['model'])\n",
    "st_model = model.build_model(model_args, task)\n",
    "st_model.load_state_dict(ckpt[\"model\"], strict=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:53:46.389273Z",
     "start_time": "2024-02-26T12:53:43.423340Z"
    }
   },
   "id": "7fe075028fafd3c"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:53:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-02-26 12:53:26 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
      "2024-02-26 12:53:26 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = True\n",
      "2024-02-26 12:53:26 | INFO | fairseq.tasks.fairseq_task | batches will be rebuilt for each epoch\n",
      "2024-02-26 12:53:26 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "S2TTransformerWithCifContrast(\n  (encoder): S2TTransformerWithCifContrastEncoder(\n    (embed_tokens): Embedding(10000, 512, padding_idx=1)\n    (dropout_module): FairseqDropout()\n    (w2v_model): Wav2VecCtc(\n      (w2v_encoder): Wav2VecEncoder(\n        (w2v_model): Wav2Vec2Model(\n          (feature_extractor): ConvFeatureExtractionModel(\n            (conv_layers): ModuleList(\n              (0): Sequential(\n                (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n                (1): Dropout(p=0.0, inplace=False)\n                (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n                (3): GELU(approximate='none')\n              )\n              (1): Sequential(\n                (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n                (1): Dropout(p=0.0, inplace=False)\n                (2): GELU(approximate='none')\n              )\n              (2): Sequential(\n                (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n                (1): Dropout(p=0.0, inplace=False)\n                (2): GELU(approximate='none')\n              )\n              (3): Sequential(\n                (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n                (1): Dropout(p=0.0, inplace=False)\n                (2): GELU(approximate='none')\n              )\n              (4): Sequential(\n                (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n                (1): Dropout(p=0.0, inplace=False)\n                (2): GELU(approximate='none')\n              )\n              (5): Sequential(\n                (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n                (1): Dropout(p=0.0, inplace=False)\n                (2): GELU(approximate='none')\n              )\n              (6): Sequential(\n                (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n                (1): Dropout(p=0.0, inplace=False)\n                (2): GELU(approximate='none')\n              )\n            )\n          )\n          (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n          (dropout_input): Dropout(p=0.0, inplace=False)\n          (dropout_features): Dropout(p=0.1, inplace=False)\n          (quantizer): None\n          (project_q): None\n          (encoder): TransformerEncoder(\n            (pos_conv): Sequential(\n              (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n              (1): SamePad()\n              (2): GELU(approximate='none')\n            )\n            (layers): ModuleList(\n              (0): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (1): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (2): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (3): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (4): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (5): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (6): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (7): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (8): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (9): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (10): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n              (11): TransformerSentenceEncoderLayer(\n                (self_attn): MultiheadAttention(\n                  (dropout_module): FairseqDropout()\n                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n                )\n                (dropout1): Dropout(p=0.1, inplace=False)\n                (dropout2): Dropout(p=0.0, inplace=False)\n                (dropout3): Dropout(p=0.1, inplace=False)\n                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              )\n            )\n            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (final_proj): None\n        )\n        (final_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ctc_proj): Linear(in_features=512, out_features=10000, bias=True)\n      (cif_proj): Linear(in_features=512, out_features=10000, bias=True)\n      (subsample_audio): Conv1dSubsampler(\n        (conv_layers): ModuleList(\n          (0): Conv1d(768, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n          (1): Conv1d(512, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n        )\n      )\n      (cif_layer): CIFLayer(\n        (weight_predictor): WeightPredictor(\n          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=same)\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=True)\n          (proj): Linear(in_features=512, out_features=1, bias=True)\n          (gelu): GELU(approximate='none')\n          (self_attention): MultiheadAttention(\n            (dropout_module): FairseqDropout()\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n        )\n      )\n    )\n    (positional_embed): SinusoidalPositionalEmbedding()\n    (transformer_layers): ModuleList(\n      (0): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (1): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (2): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (3): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (4): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (5): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout_module): FairseqDropout()\n        (activation_dropout_module): FairseqDropout()\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (decoder): TransformerDecoder(\n    (dropout_module): FairseqDropout()\n    (embed_tokens): Embedding(10000, 512, padding_idx=1)\n    (embed_positions): SinusoidalPositionalEmbedding()\n    (layers): ModuleList(\n      (0): TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (activation_dropout_module): FairseqDropout()\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (1): TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (activation_dropout_module): FairseqDropout()\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (2): TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (activation_dropout_module): FairseqDropout()\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (3): TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (activation_dropout_module): FairseqDropout()\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (4): TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (activation_dropout_module): FairseqDropout()\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (5): TransformerDecoderLayerBase(\n        (dropout_module): FairseqDropout()\n        (self_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (activation_dropout_module): FairseqDropout()\n        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (encoder_attn): MultiheadAttention(\n          (dropout_module): FairseqDropout()\n          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (output_projection): Linear(in_features=512, out_features=10000, bias=False)\n  )\n)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "itr = task.get_batch_iterator(\n",
    "    dataset=task.dataset(cfg.dataset.gen_subset),\n",
    "    max_tokens=cfg.dataset.max_tokens,\n",
    "    max_sentences=cfg.dataset.batch_size,\n",
    "    ignore_invalid_inputs=cfg.dataset.skip_invalid_size_inputs_valid_test,\n",
    "    required_batch_size_multiple=cfg.dataset.required_batch_size_multiple,\n",
    "    seed=cfg.common.seed,\n",
    "    num_shards=cfg.distributed_training.distributed_world_size,\n",
    "    shard_id=cfg.distributed_training.distributed_rank,\n",
    "    num_workers=cfg.dataset.num_workers,\n",
    "    data_buffer_size=cfg.dataset.data_buffer_size,\n",
    ").next_epoch_itr(shuffle=False)\n",
    "progress = progress_bar.progress_bar(\n",
    "    itr,\n",
    "    log_format=cfg.common.log_format,\n",
    "    log_interval=cfg.common.log_interval,\n",
    "    default_log_format=(\"tqdm\" if not cfg.common.no_progress_bar else \"simple\"),\n",
    ")\n",
    "if cfg.common.fp16:\n",
    "    st_model.half()\n",
    "if torch.cuda.is_available():\n",
    "    st_model.cuda()\n",
    "st_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:53:46.622083Z",
     "start_time": "2024-02-26T12:53:46.389004Z"
    }
   },
   "id": "e7f918c006f2ad29"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "sentence_sim_result = np.empty((0,))\n",
    "for sample in progress:\n",
    "    sample = utils.move_to_cuda(sample)\n",
    "    with torch.no_grad():\n",
    "        # speech repr\n",
    "        speech_repr = st_model.encoder(\n",
    "            sample['net_input']['src_tokens'],\n",
    "            sample['net_input']['src_lengths'],\n",
    "            sample['net_input']['transcript_lengths'],\n",
    "            is_audio_input=True\n",
    "        )['encoder_out'][0].transpose(0, 1)  # B T C\n",
    "        # text repr\n",
    "        text_repr = st_model.encoder(\n",
    "            sample['source'],\n",
    "            sample['source_lengths'],\n",
    "            transcript_lengths=None,\n",
    "            is_audio_input=False\n",
    "        )['encoder_out'][0].transpose(0, 1)\n",
    "        tok_sim = torch.nn.functional.cosine_similarity(speech_repr, text_repr, dim=-1)  # B T\n",
    "        sentence_sim = tok_sim.mean(dim=-1).cpu().numpy()\n",
    "        sentence_sim_result = np.append(sentence_sim_result, sentence_sim, axis=0)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:55:43.317756Z",
     "start_time": "2024-02-26T12:53:46.621058Z"
    }
   },
   "id": "1591ab13fab5237b"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70973051 0.78528988 0.74959624 ... 0.63203013 0.45341763 0.54352778]\n"
     ]
    }
   ],
   "source": [
    "print(sentence_sim_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:55:43.405119Z",
     "start_time": "2024-02-26T12:55:43.363022Z"
    }
   },
   "id": "a0bc163e2a2eae1"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46a5615a0d12b950"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 13:01:12 | INFO | matplotlib.font_manager | generated new fontManager\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Axes: ylabel='Density'>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABA40lEQVR4nO3dd3hc5YEu8PdMVRuNepes4iL3io0NpjoEnIAJyYUbEjAkJGQxuUl82QuGLN6EEJNsILDAOo0SFogTCJAsEMCYYIPBvcndsqrV+0gjTT3n/jHFlqtmNJrvnJn39zzz2B6N0OuDJb362pEURVFAREREpEI60QGIiIiIzoVFhYiIiFSLRYWIiIhUi0WFiIiIVItFhYiIiFSLRYWIiIhUi0WFiIiIVItFhYiIiFTLIDrAaMiyjObmZlgsFkiSJDoOERERjYCiKOjv70dBQQF0uvOPmWi6qDQ3N6O4uFh0DCIiIgpDY2MjioqKzvsaTRcVi8UCwPcXTU1NFZyGiIiIRsJms6G4uDj4ffx8NF1UAtM9qampLCpEREQaM5JlG1xMS0RERKrFokJERESqxaJCREREqsWiQkRERKrFokJERESqxaJCREREqsWiQkRERKrFokJERESqxaJCREREqsWiQkRERKrFokJERESqxaJCREREqsWiQkRERKql6bsnExFR+D6r7sQfPq2F3emByaDDlIJUfOuSMuSmJoiORhTEokJEFGfa+x34yd8P4p2qlmHPf3KsEy98WodbLirG/7t2EiwJRkEJiU5iUSEiiiNDLi+WP78dh1ps0EnANxaMw4LyDNidHry24wR21Pfgv7fUY9OxDjz99dmYUZQmOjLFORYVIqI4oSgKHnqzCodabMhKMeGP35qPqQXW4NtvuagEn1V34l9f34f6rkF8de1nWH39VHzz4nECU1O842JaIqI48dLn9XhjdxP0OgnP3DpnWEkJWDQ+C+/+n8W4dmoe3F4FP35rPx56swpurywgMRGLChFRXGi3ObDmH4cAAKuuq8TF5ZnnfK01yYi135yD+6+thCQBr2xtwDf/sBVdA85oxSUKYlEhIooDT39UDYdbxtxx6fj2pWUXfL0kSfiXKyrwh9vnIcVswNbabtzwzGYcarFFIS3RSSwqREQxrqFrEH/a1gAA+NcvToIkSSN+36sn5+LNexahNDMJTb1D+Oraz/De/pYLvyNRhLCoEBHFuCc3HIVHVrB4QtZ5p3zOZUKuBW+tuASXjs/CoMuL7728C09+eBSKooxBWqLhWFSIiGJYXacdb+1uAuAbTQlXWpIJL955Eb51iW/a6MkPj+Hf/rYfssyyQmOLRYWIKIa9srUesgJcMSl71GeiGPQ6PHz9FKy5aTokCXh5SwMefLOKZYXGFIsKEVGMcri9+MuOEwCA2xdG7iyUr88vwRM3z4ROAtZtb8Rj7x2O2H+b6HQsKkREMertfS3oG3KjMC0Rl0/Mieh/+yuzi/DEzbMAAL/bVIMPDrRG9L9PFMCiQkQUo17eUg8AuHVBCfS6ke/0GakbZxcGtzrf99peNHYPRvxjELGoEBHFoP1NfdjT2AujXsLN84rH7OPcf20lZpekwebw4Ed/3sOdQBRxLCpERDHotR2NAIBrpuYh22Ies49jMujw9NdnI8Gow476Hrx/oG3MPhbFJxYVIqIY4/bKeHuf71C2r80pGvOPV5SehLsuLQcA/PL9w/DwvkAUQSwqREQxZnN1J7rsLmQkm3DphKyofMzvXl6O9CQjajrswZ1GRJHAokJEFGP+tqcZAPDlGfkw6qPzZT41wYjvXzUBAPDrD4/C4fZG5eNS7GNRISKKIYMuD973bxVeNqswqh/7GxeXIN+agI5+ZzAD0WixqBARxZD1B9sw6PKiJCMJc0rSovqxzQY9/vdFJQCAV7c2RPVjU+xiUSEiiiH/s9c37bNsVkFId0mOlJsvKoJOArbWduN4x0DUPz7FHhYVIqIY0e9wY9PRTgDAl2cUCMmQb03EVZW+U3DXbeOoCo0eiwoRUYz46HA7XF4Z5VnJmJibIizH1+f7pn9e33kCTg8X1dLosKgQEcWIwALWa6flCZn2Cbh8YjbyrQnoGXRjw6F2YTkoNrCoEBHFgCGXF/883AEAuG5avtAsBr0ON8z0TT3xZoU0WiwqREQxYOPRDgy5vShKT8S0wlTRcfCFKbkAfNNRbp5US6PAokJEFAPe2+87Mv/aqWKnfQJml6QjM9kEm8ODbbXdouOQhrGoEBFpnMsjY8Nh31qQa6flCU7jo9dJWDLZN6qy/iBvVEjhY1EhItK47XXd6Hd4kJViwpySdNFxggLTPx8caIWiKILTkFaxqBARaVxgxOKqyhzodOKnfQIunZCFRKMezX0OHGi2iY5DGsWiQkSkYYqiYMNhX1G52j/VohYJRj0W++/ezOkfCheLChGRhh1rH0Bj9xBMBl2wFKhJYJ3Kp9WdgpOQVrGoEBFp2IeHfCMViyoykWQyCE5zpoUVmQCAvY29sDs9gtOQFrGoEBFpWODk1yUqm/YJKM5IQlF6Ijyygu113KZMoWNRISLSqK4BJ3Y19AAArp6cIzjNuS0s942qfF7TJTgJaRGLChGRRm082gFFAabkpyLfmig6zjkFpn+2HGdRodCxqBARadSmo757+1wxKVtwkvMLFJWqpj7YHG7BaUhrWFSIiDRIlhVsOubbSXP5RHUXlXxrIsqykiErwLYarlOh0LCoEBFp0P7mPnTbXUgxGzBnnHpOoz2Xi7lOhcLEokJEpEGBaZ9FFZkw6tX/pXyRf/rnM65ToRCp/183ERGdYaO/qFyu8vUpAQvKMgAAR1ptGOB5KhQCFhUiIo2xOdzY1dALALhsgjaKSk5qAgrTEiErwL7GXtFxSENUU1Qee+wxSJKEH/7wh6KjEBGp2mfVnfDKCsqzk1GckSQ6zojNLkkDgODZL0QjoYqisn37dvz2t7/FjBkzREchIlK9T/y7fbQymhIwu8S36He3fzSIaCSEF5WBgQF84xvfwO9//3ukp6t/5ToRkWif+xekXjpefTchPJ85/hGV3Y29UBRFbBjSDOFFZcWKFfjSl76EJUuWXPC1TqcTNptt2IOIKJ609A2hptMOnQTML88QHSckUwpSYdLr0G13ob5rUHQc0gihRWXdunXYtWsX1qxZM6LXr1mzBlarNfgoLi4e44REROoSGE2ZXpSG1ASj4DShMRv0mFqYCoDrVGjkhBWVxsZG/OAHP8Arr7yChISEEb3PqlWr0NfXF3w0NjaOcUoiInUJnEMSOJdEa+ZwnQqFyCDqA+/cuRPt7e2YM2dO8Dmv14tNmzbhmWeegdPphF6vH/Y+ZrMZZrM52lGJiFRBUZTgiIpWi8rs4DoVjqjQyAgrKldffTWqqqqGPXfnnXeisrIS999//xklhYgo3jV0D6KpdwhGvYR547S1PiUgMKJyqKUfgy4PkkzCvg2RRgj7F2KxWDBt2rRhzyUnJyMzM/OM54mI6OS0z+ySdCSatPnDXL41ATkWM9r7nTjQbMNFpdosXBQ9wnf9EBHRyGh9fQoASJKE6YVWAMD+pj7BaUgLVDXm9vHHH4uOQESkSoqiYKv/zsOBOxFr1bRCKzYcbkcViwqNAEdUiIg0oLF7CO39Thj1EmYVp4mOMyrT/CMqB5p4FhZdGIsKEZEGbK/rBgBML7QiwajN9SkBgamfY+39GHJ5BachtWNRISLSgB31vqJyUZn2F5/mppqRlWKGrAAHWziqQufHokJEpAHbav1FRaPbkk/lW1DrO6H2QDPXqdD5sagQEalc14ATxzvsAIC542Lj5q2BdSpVJ1hU6PxYVIiIVG5nve8U1wk5KUhPNglOExnBosKdP3QBLCpERCq3w19U5sXQ4WgnF9QOwOHmglo6NxYVIiKVC+z4mV8WG9M+gO+E2oxkE7yygsOt/aLjkIqxqBARqZjD7Q2e4KrV+/ucjSRJwekfnlBL58OiQkSkYvub+uD2Ksi2mFGUnig6TkRNyfft/DnELcp0HiwqREQqtqexFwAwqzgNkiSJDRNhk/MtAFhU6PxYVIiIVGz3KUUl1kz2j6gcae2HLCuC05BasagQEanYXn9RmR2DRaU8Kxkmgw52lxeNPYOi45BKsagQEalU54ATJ3qGIEnA9CKr6DgRZ9DrMDE3BQBwqIU7f+jsWFSIiFRqT0MvAGB8dgosCUaxYcZIZR4X1NL5sagQEanUnhhenxIwmTt/6AJYVIiIVCpYVErShOYYS4GdPzz0jc6FRYWISIVkWQkupI3pERX/1E9D9yD6HW7BaUiNWFSIiFSopnMA/U4PEo16TMq1iI4zZtKTTchLTQAAHG3jqAqdiUWFiEiF9jb6jpWfVpgKgz62v1RX+qd/DnLnD51FbP/rJyLSqP3NgaISe9uST8cFtXQ+LCpERCp0oMn3TXt6HBSVyjzfiMpRLqils2BRISJSGVlWcCCORlQm+YvKkbZ+KAqP0qfhWFSIiFSmtssOu8uLBKMO5VnJouOMufKsFBh0EvodHrTaHKLjkMqwqBARqcz+Jt9oypT82F9ICwAmgw5l/kJ2hNM/dJrY/wwgItKYA82+9SnxMO0TMNG/BftY24DgJKQ2LCpERCpTdcK/PqUg/orKEZ6lQqdhUSEiUhFFUYJbk6cWpgpOEz2T8nx3Ueahb3Q6FhUiIhVp7B5Cv8MDk14XHGWIB4G/69G2fsgyd/7QSSwqREQqUuVfSFuZb4ExDhbSBozLTIbJoIPDLaOxZ1B0HFKR+PksICLSgOC0TxytTwEAvU7C+OzA9A8X1NJJLCpERCoSOEZ+SkH8rE8JCBz8xnUqdCoWFSIiFQkWlfz4WZ8SENz5w7NU6BQsKkREKtFtd6HN5gQATMqLxxEV7vyhM7GoEBGpxGH/aEpJRhJSzAbBaaJvQo5vROV4xwA8XllwGlILFhUiIpU46C8qk+Nw2gcACtMSkWjUw+1V0NgzJDoOqQSLChGRShz2r82YnB9/0z4AoNNJKM/23fOnup07f8iHRYWISCUCC2kr43B9SkCFf4syiwoFsKgQEamA2ysHb8g3JU5HVABgfA6LCg3HokJEpAK1nXa4vDJSzAYUpSeKjiNMoKgc72BRIR8WFSIiFQhM+0zKs0CnkwSnESdYVNoHoCi85w+xqBARqcKhlsBC2vjc8RMwLjMJOgnod3rQ3u8UHYdUgEWFiEgFuJDWx2zQY1ymb+fPca5TIbCoEBGpwpFWjqgEBHf+cJ0KgUWFiEi4vkE3Wm0OACfvdxPPKnJ4lgqdxKJCRCTY0XbfaEphWiIsCUbBacQbz7NU6BQsKkREggVuwjchN0VwEnXgFmU6FYsKEZFgR/3rUyZx2gcAUOEvKm02J2wOt+A0JBqLChGRYEf8Iypcn+KTmmBEjsUMgDt/iEWFiEi4o/6j81lUTuJR+hTAokJEJFDngBPddhck6eQ3Zzp1nYpdcBISjUWFiEigwPqUcRlJSDTpBadRD95FmQJYVIiIBDoS3PHDaZ9TcecPBbCoEBEJFFifwh0/wwWKSkP3IJwer+A0JBKLChGRQIEzVCbmsaicKsdihsVsgFdWUN81KDoOCcSiQkQkiKIowTUqE3nY2zCSJKGcO38ILCpERMK02hzod3qg10koy0oWHUd1eJQ+ASwqRETCHPOvTynNTILZwB0/p+OCWgJYVIiIhAmMFPD8lLOryOZdlIlFhYhImGP+b8ATcriQ9mxOHVGRZUVwGhKFRYWISJDjHFE5r5KMJJj0OjjcMpr7hkTHIUFYVIiIBKnuYFE5H4Neh9KsJACc/olnLCpERAJ0nXKPn8Bx8XQmHqVPLCpERAIEvvEWpiXyHj/nESgqtZ28OWG8YlEhIhLgGNenjEjgfJka3kU5bgktKmvXrsWMGTOQmpqK1NRULFy4EP/4xz9ERiIiiorq4I4fFpXzKfdvUeaISvwSWlSKiorw2GOPYefOndixYweuuuoqLFu2DAcOHBAZi4hozB3nQtoRCYyotNocsDs9gtOQCEKLyvXXX4+lS5diwoQJmDhxIh599FGkpKRgy5YtImMREY25wKm043mGynmlJZmQkWwCwFGVeKWaNSperxfr1q2D3W7HwoULz/oap9MJm8027EFEpDX9DjdabQ4AHFEZicCoCotKfBJeVKqqqpCSkgKz2Yzvfe97ePPNNzFlypSzvnbNmjWwWq3BR3FxcZTTEhGN3nH/wtBsixnWRKPgNOpXzqIS14QXlUmTJmHPnj3YunUr/uVf/gXLly/HwYMHz/raVatWoa+vL/hobGyMcloiotE71tYPgAtpR6osO7Dzh2epxCOD6AAmkwnjx48HAMydOxfbt2/HU089hd/+9rdnvNZsNsNsNkc7IhFRRPFE2tBwRCW+CR9ROZ0sy3A6naJjEBGNmeo2FpVQlPsPfavptENReHPCeCN0RGXVqlW47rrrUFJSgv7+frz66qv4+OOP8f7774uMRUQ0pjiiEpqSjCRIEtDv8KBzwIVsC0fW44nQotLe3o7bb78dLS0tsFqtmDFjBt5//3184QtfEBmLiGjMONxeNHYPAmBRGakEox6FaYk40TOE2k47i0qcEVpUnnvuOZEfnogo6mo67JAVwJpoRHYKv+GOVHl2ir+oDGB+WYboOBRFqlujQkQUy06d9pEkSXAa7SjnPX/iFosKEVEUVfu3Jo/P5rRPKII3J+TOn7jDokJEFEWBEZUJuSwqoeDptPGLRYWIKIoCd02u4ELakATuolzfZYfHKwtOQ9HEokJEFCUerxwcEeDUT2gKrIkwGXRwexU09Q6JjkNRxKJCRBQl9d2DcHsVJPq329LI6XQSyjK5TiUesagQEUXJsbbAtE8ydDru+AlVYPqnljt/4gqLChFRlBwPLKTNsQhOok0nd/7w5oTxhEWFiChKAgtpeSJteLjzJz6xqBARRcmxdv8ZKiwqYeHUT3xiUSEiigJZVoIjKhNYVMJSnuW7bs19Dgy6PILTULSwqBARRcGJniE43DJMeh1KMpJEx9Gk9GQT0pKMAIC6zkHBaShaWFSIiKIgMO1Tnp0Mg55fesPFdSrxh58tRERRcCww7ZPLHT+jEZj+qengzp94waJCRBQFgTNUuD5ldIILajmiEjfCKio1NTWRzkFEFNOq/VM/LCqjw7sox5+wisr48eNx5ZVX4uWXX4bD4Yh0JiKimKIoyilTPywqoxEYUanpGICiKILTUDSEVVR27dqFGTNmYOXKlcjLy8Pdd9+Nbdu2RTobEVFM8G2n9cKgkzDOf78aCk+p//rZHB50212C01A0hFVUZs2ahaeeegrNzc14/vnn0dLSgksvvRTTpk3DE088gY6OjkjnJCLSrGNtvmmfsqxkGLnjZ1QSjHoUWBMAAHVdnP6JB6P6jDEYDLjpppvw2muv4Re/+AWqq6tx3333obi4GLfffjtaWloilZOISLMCB71N5I6fiCgLTv+wqMSDURWVHTt24J577kF+fj6eeOIJ3HfffTh+/DjWr1+P5uZmLFu2LFI5iYg062gbj86PJJ6lEl8M4bzTE088gRdeeAFHjhzB0qVL8dJLL2Hp0qXQ6Xy9p6ysDC+++CJKS0sjmZWISJO4kDayyvxnqbCoxIewisratWvxrW99C3fccQfy8/PP+pqcnBw899xzowpHRKR1iqKgOniGCqd+IqEsy3cLAhaV+BBWUVm/fj1KSkqCIygBiqKgsbERJSUlMJlMWL58eURCEhFpVZvNiX6nB3qdhNIs3uMnEgIjKnVddsiyAp1OEpyIxlJYa1QqKirQ2dl5xvPd3d0oKysbdSgiolgRuMfPuMwkmA16wWliQ1F6Igw6CQ63jFYbz/KKdWEVlXMdsjMwMICEhIRRBSIiiiU8Oj/yjKfcgbqO0z8xL6Spn5UrVwIAJEnCww8/jKSkk8OYXq8XW7duxaxZsyIakIhIy45xa/KYKM1KRk2nHTWddiwanyU6Do2hkIrK7t27AfhGVKqqqmAymYJvM5lMmDlzJu67777IJiQi0rDAPX64NTmyuEU5foRUVP75z38CAO6880489dRTSE1NHZNQRESxQFEUHOWOnzHBohI/wtr188ILL0Q6BxFRzOkYcKJvyA2ddPJmehQZgaLCNSqxb8RF5aabbsKLL76I1NRU3HTTTed97RtvvDHqYEREWhc4P6UkIwkJRu74iaRAUWnoHoTbK/MeSjFsxEXFarVCkqTg74mI6PwCC2nHc9on4vJSE5Bg1MHhlnGiZyhYXCj2jLionDrdw6kfIqILC5yhMpFH50ecTiehNDMZh1v7UddpZ1GJYWGNlQ0NDWFwcDD45/r6ejz55JP44IMPIhaMiEjrgmeosKiMiUA5qeE6lZgWVlFZtmwZXnrpJQBAb28v5s+fj8cffxzLli3D2rVrIxqQiEirqtu542csndz5MyA4CY2lsIrKrl27sHjxYgDA66+/jry8PNTX1+Oll17Cf/7nf0Y0IBGRFnXbXeiyuyBJQEU2R1TGArcox4ewisrg4CAsFt9PCB988AFuuukm6HQ6XHzxxaivr49oQCIiLTrcagPguy9Nook7fsZCYMt3XefgBV5JWhZWURk/fjzeeustNDY24v3338c111wDAGhvb+chcEREAA63+BbSTs7j18SxUprpKypNvUNwuL2C09BYCauoPPzww7jvvvtQWlqKBQsWYOHChQB8oyuzZ8+OaEAiIi0KjKhU5rOojJWMZBNSE3ybV+u6OP0Tq8IqKl/72tfQ0NCAHTt24L333gs+f/XVV+PXv/51xMIREWnVIf+IypR8LqQdK5Ikocy//ocn1MausI7QB4C8vDzk5eUNe27+/PmjDkREpHUer4yjbb6iUsmpnzFVnpWMvY293KIcw8IqKna7HY899hg2bNiA9vZ2yLI87O01NTURCUdEpEV1XYNwemQkmfQoyUgSHSemBdap1HawqMSqsIrKXXfdhY0bN+K2225Dfn5+8Gh9IiICDrX41qdMyrNAp+PXx7FUls0tyrEurKLyj3/8A++88w4uueSSSOchItK84EJaTvuMufLAXZS5mDZmhbWYNj09HRkZGZHOQkQUE4Jbk7mQdsyV+otK54ALfUNuwWloLIRVVB555BE8/PDDw+73Q0REPoGpn8ncmjzmUswGZFvMALjzJ1aFNfXz+OOP4/jx48jNzUVpaSmMRuOwt+/atSsi4YiItKZv0I3mPgcA3xoVGntlWcno6HeirsuOmcVpouNQhIVVVG688cYIxyAiig2H/OtTCtMSkZpgvMCrKRLKs5KxrbYbNdz5E5PCKiqrV6+OdA4iophwctqHoynRUsqbE8a0sNaoAEBvby/+8Ic/YNWqVeju7gbgm/JpamqKWDgiIq3Z3+QrKlMLrIKTxA/eRTm2hTWism/fPixZsgRWqxV1dXX4zne+g4yMDLzxxhtoaGjASy+9FOmcRESasL+pDwAwvZBFJVqCW5Q77VAUhWd7xZiwRlRWrlyJO+64A8eOHUNCQkLw+aVLl2LTpk0RC0dEpCVDLi+Otfu2Jk8vYlGJlpLMJEgS0O/0oHPAJToORVhYRWX79u24++67z3i+sLAQra2tow5FRKRFB1tskBUg22JGbmrChd+BIsJs0KMwLREAp39iUVhFxWw2w2aznfH80aNHkZ2dPepQRERaxGkfccpOmf6h2BJWUbnhhhvw05/+FG637xRASZLQ0NCA+++/H1/96lcjGpCISCv2nfAVlWksKlEXWKfCuyjHnrCKyuOPP46BgQFkZ2djaGgIl19+OcaPHw+LxYJHH3000hmJiDSBIyrinNyiPCA4CUVaWLt+rFYr1q9fj82bN2Pv3r0YGBjAnDlzsGTJkkjnIyLShGELaVlUoo5blGNXyEVFlmW8+OKLeOONN1BXVwdJklBWVoa8vDxuCyOiuBVYSJuVYkZuqll0nLhTnpUCAKjrGoQsK9Dp+L0oVoQ09aMoCm644QbcddddaGpqwvTp0zF16lTU19fjjjvuwFe+8pWxyklEpGonp31S+QObAIXpiTDqJbg8Mpr7hkTHoQgKaUTlxRdfxKZNm7BhwwZceeWVw9720Ucf4cYbb8RLL72E22+/PaIhiYjUrorrU4TS6ySUZCTheIcdtZ12FKUniY5EERLSiMqf/vQnPPjgg2eUFAC46qqr8MADD+CVV16JWDgiIq3Y09gLAJhelCY0RzwrC0z/cJ1KTAmpqOzbtw/XXnvtOd9+3XXXYe/evaMORUSkJX1DblS3+3abzC5JExsmjpVnc4tyLAqpqHR3dyM3N/ecb8/NzUVPT8+oQxERaUlgNGVcZhKyUriQVhTu/IlNIRUVr9cLg+Hcy1r0ej08Hs+oQxERacmuet8PaHNK0gUniW+lmSwqsSikxbSKouCOO+6A2Xz2nxicTmdEQhERaclu/4gKp33ECkz9nOgZgssjw2QI60xTUpmQisry5csv+Bru+CGieCLLCnY3cERFDXIsZiSZ9Bh0edHYM4iK7BTRkSgCQioqL7zwQkQ/+Jo1a/DGG2/g8OHDSExMxKJFi/CLX/wCkyZNiujHISIaK8c7BtDv8CDRqEdlnkV0nLgmSRJKM5NxsMWG2g47i0qMEDoutnHjRqxYsQJbtmzB+vXr4Xa7cc0118Bu5/wiEWnDLv9oyowiKwx6TjWIVuaf/qnr4veRWBHWvX4i5b333hv25xdffBE5OTnYuXMnLrvsMkGpiIhGbndDLwBgzjhO+6gB76Ice4QWldP19flOdszIyDjr251O57AFuzabLSq5iIjOJTCiMrs4TWwQAnDKFuUOFpVYoZpxSlmW8cMf/hCXXHIJpk2bdtbXrFmzBlarNfgoLi6OckoiopP6Bt045j/ojSMq6lDKs1RijmqKyooVK7B//36sW7funK9ZtWoV+vr6go/GxsYoJiQiGm5bXTcUBajITuZBbyoRmPpptTkw6OK5XrFAFVM/9957L95++21s2rQJRUVF53yd2Ww+5xkuRETRtq22CwAwvyxTcBIKSEsyIT3JiJ5BN+o6BzGlIFV0JBoloSMqiqLg3nvvxZtvvomPPvoIZWVlIuMQEYVkW203AGBB2dnX1ZEYPEo/tggtKitWrMDLL7+MV199FRaLBa2trWhtbcXQ0JDIWEREFzTg9GB/s29B/3wWFVUJrFPhFuXYILSorF27Fn19fbjiiiuQn58ffPz5z38WGYuI6IJ21vfAKysozkhEQVqi6Dh0iuAWZe78iQlC16goiiLywxMRhW1rjW99ygKuT1GdsizfibS1nQOCk1AkqGbXDxGRlgTWp3DaR31Ks5IAcI1KrGBRISIKkcPtxd4TvQC4kFaNAotpewbd6B10CU5Do8WiQkQUol31PXB7FeSlJqAkI0l0HDpNksmAAmsCAOA416loHosKEVGIPjvuW5+ysCITkiQJTkNnU5HjW6dyvIPrVLSORYWIKESbj3cCABZVcCGtWlVk+4tKO4uK1rGoEBGFoN/hxr4TvhuoLhqfJTgNnUtFtm+dCkdUtI9FhYgoBNtqu+GVFZRmJqGQ56eoVnBEhWtUNI9FhYgoBJurA+tTOJqiZoE1Kg3dg3B6vILT0GiwqBARheAz//qUS8ZzfYqa5VjMSDEb4JUVNHQNio5Do8CiQkQ0Qp0DThxu7QcALCxnUVEzSZK4TiVGsKgQEY3Q5/5tyZV5FmSmmAWnoQvhOpXYwKJCRDRCm6sD25K5PkULgmepcIuyprGoEBGNgKIo+OSYr6gsnsiiogWc+okNLCpERCNQ1zWIpt4hmPQ63t9HI06d+lEURXAaCheLChHRCHxyrAMAMGdcGpJMBsFpaCRKMpOg10kYcHrQZnOKjkNhYlEhIhqB4LTPhGzBSWikzAZ98KaR1VynolksKkREF+Dxytji3/FzKY/N15ST0z8sKlrFokJEdAF7T/Si3+lBWpIR0wqtouNQCCbk+orKsfZ+wUkoXCwqREQXEJj2uaQiC3qdJDgNhWKCf4vy0TaOqGgViwoR0QUEisqlEzjtozUTcy0AuEZFy1hUiIjOw+ZwY09jLwCuT9GiiuwUSBLQbXeha4A7f7SIRYWI6Dy2HO+CV1ZQmpmEYv8OEtKORJMeRemJADj9o1UsKkRE5/FpNbcla93EnMD0DxfUahGLChHReXzK9SmaNz6484cjKlrEokJEdA4negZR02mHXidhYUWm6DgUpgn+EZVjnPrRJBYVIqJzCIymzCyyIjXBKDgNhSuwRZlnqWgTiwoR0Tl8Uh2Y9uH6FC0b7y8qnQMudNtdgtNQqFhUiIjOQpYVfOYvKpdxfYqmJZsNKEzz7fzheSraw6JCRHQWB5pt6Bl0I8VswMziNNFxaJQCR+kfbeP0j9awqBARncWmYx0AgIvLM2HU80ul1gVOqD3GoqI5/OwjIjqLwELaxZz2iQmBBbVHWFQ0h0WFiOg0Qy4vdtb3AOD5KbFicn4qAOBIaz8URRGchkLBokJEdJqttV1weWUUpiWiPCtZdByKgPE5KdBJQM+gG+39vOePlrCoEBGdJnga7fgsSJIkOA1FQoJRj1J/6TzcyukfLWFRISI6zSc8Nj8mVeb5FtQeabUJTkKhYFEhIjpFu82BI239kCTgkvEsKrGkMs+3ToUjKtrCokJEdIrA3ZKnFqQiI9kkOA1F0iT/iMrhFhYVLWFRISI6xcltyTw2P9YEpn6qOwbg8cqC09BIsagQEfkpihK8v89iTvvEnOL0JCSZ9HB5ZNR12UXHoRFiUSEi8jvS1o+OficSjDrMLU0XHYciTKeTgifUcp2KdrCoEBH5BaZ95pdlwmzQC05DY6GS61Q0h0WFiMgvsC2Z0z6xK7igliMqmsGiQkQEwOnxYmttFwBg8UQWlVh1cosyz1LRChYVIiIAO+t74HDLyLaYMcm/joFiz+R83//bEz1D6BtyC05DI8GiQkSEU06j5bH5MS0tyYTCtEQAwKEWjqpoAYsKERGAj490AAAu47RPzJtS4Jv+OdDMoqIFLCpEFPda+xw41GKDJAGX8aC3mDc1WFT6BCehkWBRIaK4t/FoOwBgRlEaMlPMgtPQWJtaYAUAHOSIiiawqBBR3AtM+1w5iaMp8SAw9VPdPgCnxys4DV0IiwoRxTW3Vw4e9HbFpBzBaSgaCqwJSEsywiMrONY2IDoOXQCLChHFtZ31Peh3epCZbMKMQqvoOBQFkiRhSj7XqWgFiwoRxbV/HvGtT7lsYjZ0Om5LjheBBbVcp6J+LCpEFNc2+tenXMH1KXElsKCWW5TVj0WFiOJWS98QDrf2Q8dtyXEnsKD2UIsNsqwITkPnw6JCRHErsNtnZnEa0pNNgtNQNJVnJcNs0MHu8qKuyy46Dp0HiwoRxa2P/etTruRun7hj0OuCoypVTVxQq2YsKkQUl1yeU7clc9onHgV2eVWdYFFRMxYVIopLO+q7YXd5kZViwrQCbkuOR9OL0gAA+ziiomosKkQUl07ehJDbkuPVjCL/zp+mPni5oFa1WFSIKC5xfQpVZKcg0aiH3eVFbSdPqFUrFhUiijsnegZxtG0AOglYPCFLdBwSRK+Tgge/7eM6FdViUSGiuLP+YBsAYF5pBtKSuC05nk33T/+wqKgXiwoRxZ0PDviKyjVTcgUnIdEC61S4RVm9WFSIKK70Drqwra4bAHDNlDzBaUi06YVpAHw3J/R4ZbFh6KxYVIgornx0uB1eWUFlngUlmUmi45Bg5VnJSDbp4XDLqO7gglo1ElpUNm3ahOuvvx4FBQWQJAlvvfWWyDhEFAcC61O+wGkfAqDTSZjmP/htXyOnf9RIaFGx2+2YOXMmnn32WZExiChOONxebDzqOz+F0z4UMLM4DQCwu7FXaA46O4PID37dddfhuuuuExmBiOLI5upODLq8yLcmYFphqug4pBKz/EVlD4uKKnGNChHFjXerWgH4dvtIEk+jJZ/ZJWkAgCOtNgy6PGLD0Bk0VVScTidsNtuwBxHRSLg8MtYf9BWVpdPzBachNcm3JiI31QxZ4Q0K1UhTRWXNmjWwWq3BR3FxsehIRKQRm6s7YXN4kG0xY15phug4pDKc/lEvTRWVVatWoa+vL/hobGwUHYmINOKdqhYAwHXT8qDnTQjpNLOK0wGwqKiR0MW0oTKbzTCbzaJjEJHGuDwyPjjAaR86N46oqJfQojIwMIDq6urgn2tra7Fnzx5kZGSgpKREYDIiiiWbj/umfbJSzLiI0z50FjOKrNBJQEufA202B3JTE0RHIj+hUz87duzA7NmzMXv2bADAypUrMXv2bDz88MMiYxFRjHlnn2/aZ+l0TvvQ2SWbDZiYawEA7G7oFRuGhhE6onLFFVdAURSREYgoxjncXry33zft8+UZBYLTkJrNLknD4dZ+7GnsxbXTeCCgWmhqMS0RUag+PNSGAacHhWmJmDcuXXQcUrHAOpVdDT1ig9AwLCpEFNPe2t0MAFg2qwA6TvvQecz1F9m9jb1w807KqsGiQkQxq8fuwsaj7QCAG2cXCk5DaleelQJrohFOj4yDzTxQVC1YVIgoZr1T1QK3V8GU/NTgQkmic9HppOCoys56Tv+oBYsKEcWsv+1pAgDcOJuLaGlkgkWF61RUg0WFiGJSTccAttf1QCcBN8zktA+NzJwSX1HZxREV1WBRIaKY9NrOEwCAyydmI8/Kw7toZGYWW6HXSWjpc6C5d0h0HAKLChHFII9Xxl/9ReXmebx5KY1cksmAKfmpALhORS1YVIgo5nx8pAPt/U5kJptw9eRc0XFIY7igVl1YVIgo5vxlh+/O6l+ZXQiTgV/mKDSBosKD39SBn8FEFFPa+x346LDv7JSbL+K0D4UuUFQONNtgd3oEpyEWFSKKKeu2NcIjK5hTksazUygsBWmJKExLhFdWOKqiAiwqRBQz3F4Zr25tAADcvrBUbBjStPllGQCA7bXdgpMQiwoRxYz1B9vQanMgM9mE66bz7rcUvkBR2cqiIhyLChHFjJc+rwMAfH1+CcwGvdgwpGkXlfqKyp7GXjg9XsFp4huLChHFhKNt/dhS0w2dBNy6oER0HNK4iuxkZCab4PTIqDrRJzpOXGNRIaKY8NwntQCAL0zJRUFaouA0pHWSJAVHVbbVcfpHJBYVItK8dpsDb+723YDwu5eVC05DsSKwTmUb16kIxaJCRJr3wmd1cHllzB2XjrnjMkTHoRgRKCo763rglRXBaeIXiwoRaVq/w42Xt9QDAO7maApF0OT8VKSYDeh3enCoxSY6TtxiUSEiTVu3rRH9Dg/Ks5OxhPf1oQjS6yRcVOo7pfbz412C08QvFhUi0qwhlxe/3VQDwDeaotNJghNRrFlUkQUA+LyGRUUUFhUi0qyXt9Sjc8CJ4oxE3DSnSHQcikELKzIBAFtruuD2yoLTxCcWFSLSJLvTg7UbjwMAvn/VBBj1/HJGkTclPxXWRCPsLi+qmnieigj8zCYiTfrj53XotrtQmpmEm2YXio5DMUqnk3BxuW/3D9epiMGiQkSa0zfoxm83+tam/GDJBBg4mkJjKLhOhUVFCH52E5HmPLXhGPqG3JiUa8ENMzmaQmMrsE5lR3037/sjAIsKEWlKTcdA8OaDP/7yZOi504fG2IScFGSlmOBwy9jT0Cs6TtxhUSEiTfn5u4fhkRVcVZmDxROyRcehOCBJEhb6p382V3cKThN/WFSISDM2Hu3Ah4faoNdJeHBppeg4FEcWT/AVlY3HWFSijUWFiDRhyOXFj9+qAgAsX1iK8TkWwYkonlw+0Td6t+9EL7oGnILTxBcWFSLShKc/OobG7iHkWxOw8pqJouNQnMlNTcDk/FQoCvApp3+iikWFiFTvSGs/fuc/Kv8nN0xFitkgOBHFo8CoysYjHYKTxBcWFSJSNbdXxv99bQ88soJrpuTimql5oiNRnAoUlU3HOiDLiuA08YNFhYhU7emPqrG/yYa0JCN+duM00XEojs0dl45kkx6dAy4cbLGJjhM3WFSISLX2NPbi2X9WAwB+duM05KQmCE5E8cxk0GHReP/un6Oc/okWFhUiUqUBpwc/XLcbXlnBDTML8OUZBaIjEQWnfzYcahOcJH6wqBCR6iiKggffqEJd1yAKrAn46bKpoiMRAQCWTM4FAOxq6EW7zSE4TXxgUSEi1fnz9kb8fW8z9DoJT986G2lJJtGRiAAAedYEzC5JAwC8f5CjKtHAokJEqrK/qQ+r/34AAHDfNZMwd1yG4EREw13r33n23v4WwUniA4sKEalGt92Fu/97J5weGVdV5uDuy8pFRyI6wxf9RWVLTTd67C7BaWIfiwoRqYLHK+PeV3ehqXcIZVnJ+PUts6DjnZFJhUqzklGZZ4FXVvAhF9WOORYVIhJOURSs/vsBfHa8C8kmPX5321xYE42iYxGd07XTfKMq7x9oFZwk9rGoEJFwz31ai1e2NkCSgF/fMgsTcnnDQVK3QFHZdLQTfYNuwWliG4sKEQn1j6oWPPruIQDAQ0sn84h80oRJuRZU5lng8sr4+75m0XFiGosKEQnz6bFO/GDdHigKcNvF4/DtS8tERyIaEUmS8LW5RQCA13Y0Ck4T21hUiEiI3Q09+O5/74DLK2Pp9Dz8+w1TIUlcPEva8ZXZhTDoJOw70Ycjrf2i48QsFhUiirrdDT24/fltGHR5sXhCFn59yyzoucOHNCYzxYyrJ+cA4KjKWGJRIaKo2lHXjdue24Z+hwcXlabjN9+cC7NBLzoWUVhunlcMAHhzdxPcXllwmtjEokJEUfPR4Tbc/vw2DDg9uLg8A3/81nwkmw2iYxGF7fKJ2ci2mNFld+HdKp5UOxZYVIgoKl7eUo+7/rgjON3zwh3zkWRiSSFtM+h1uO3icQCAtR8fh6IoghPFHhYVIhpTDrcXq96owo/f2g9ZAf7X3CI8f8dFSDRxuodiw/KFpUg26XG4tR//PNIuOk7MYVEhojFT3d6Pr/zXZ/jTNt9hbvddMxG//NoMGPX80kOxw5pkxDcX+kZVnvmomqMqEcavFkQUcU6PF79efxTXPfUJDrXYkJlswkvfmo97r5rALcgUk759aRlMBh12NfRiS0236DgxhUWFiCLG7ZXxl+2NWPLERjy14RjcXgVXVebg3R8sxuIJ2aLjEY2ZHEsCbp7nOwDukbcPwsMdQBHDlWxENGonegbx151N+MuORjT1DgEAsi1mrL5+Cr40PZ+jKBQXfrhkIv5nbwsOttjwwuY6fOeyctGRYgKLChGFRFEUtPQ5cKDZhp31Pdh0tAMHW2zBt2cmm/C9yyvwzYvHccEsxZWsFDMeXFqJ+/9ahSfWH8V10/NQlJ4kOpbmsagQ0TkpioKm3iHsO9GHvSd6caDJhgPNfeg5y91iF5Zn4uaLinDt1HwWFIpbN88rxl93NWFbbTf+9bV9+OO35sNk4CqL0ZAUDS9PttlssFqt6OvrQ2pqqug4RJqnKAqOtg3g4yPt2FLThX0n+tBld53xOr1OwoScFEwrtOLS8Vm4dEIWslLMAhITqU91+wBueOZTDLq8uGl2IR6/eSanP08TyvdvjqgQEarbB/C3PU34255mNHQPDnubQSehMt+CGUVpmF5oxdSCVEzMtSDByFETorMZn5OCZ78xB3f9cQfe2N2E7FQzHri2kmUlTCwqRHGqtc+Bt/c14609TdjfdHKNidmgw8XlmbhsYjbmlKRhcn4qSwlRiK6clIM1X5mO//fXffjtxhocb7fjV/9rBtKSTKKjaQ6LClEc6Rpw4t39rfifvc3YXteNwMSvQSfh8onZWDa7EEsm5/Boe6IIuPmiYrhlGT/5+0F8eKgNS5/6BCuuGo+vzili+Q8B16gQxTC704PDrTZsqenGp8c6sa2uG1755Kf8vHHpWDa7EF+ano+MZP6kRzQW9jf14d5Xd6GuyzetmplswpLJuVg0PhNzx6WjMC0x7qaFQvn+zaJCpBGKomDA6UHvoBs9gy70DLrRO+jCgNMDu9ODAacXg04PegbdaLUN4UTPEBq6B3H6Z/j0Qiuun5mPL88oQEFaopi/DFGcGXR5sG5bI577tDZ41lCAxWzApDwLJuVZUJlnwaS8VEzKs8CaaBSUduyxqBBpnNsro6qpD3sbe1F1og/H2gdQ22nHgNMT8n8r22LG3JJ0LBqficUTslGWlTwGiYloJDxeGZ9Wd2JzdSc+O96Fo239cHvP/m24wJqASXkWzClJx5WVOZiSnwqdLjZGXlhUiDSovsuOTcc68cnRDnx+vAv95yglCUYd0hJNSEsyIi3JiBSzESlmPZLNBqSYDUhNNCLfmoB8ayIm5qYgk9uGiVTL5ZFR22nH4VYbDrf243CLDUda+9Hc5zjjtdkWM66YmI0rK3OweEIWLAnaHXHRXFF59tln8R//8R9obW3FzJkz8fTTT2P+/PkXfD8Wlfjj8sgYcnvhcHsx5PJi0OUN/jn4e/+vgy4vZEWBSa+DUS/BaNDBpNfBkuD7Zp6aYITV/2tKggH6KP+k0tHvxI66bnxa3YlPjnWesS04LcmIuSXpmFGUhsp8Cyqyk1GYlsTD1IjiQN+gG0fa+nGoxRYcgRl0eYNvN+olLCjLxJLJObh6ci6KM7R1Aq6misqf//xn3H777fjNb36DBQsW4Mknn8Rrr72GI0eOICcn57zvy6KiDk6PFz12N7rsTnTbXcMetiE3XF4FLo8Mt/fkw+VV4PbI8MoK3LIMj1eBR1bg8Z79ObdXgcPthUceu3+ulgQDUhOM/hJjgDXROPyR5C82pz+faIRRf/6TJ3sHXajrGsShFht21PVgR3036rvOPK9k7rh0XDYxG4snZGFqgTXq5YmI1Mnp8WJ7bQ/+eaQdHx1uR22nfdjby7OTMb80A/NKM3BRaTpKMpJUvUBXU0VlwYIFuOiii/DMM88AAGRZRnFxMb7//e/jgQceOO/7qrGoKIrvm6vTI8Pp9sLlleF0y8FfnR4vXB7Z93aP789OjwydJMFs0MFs0CHBqPf9PvCr/znfQ4cEg35M5indXhl2pwf9Dt9jwOlBv8ONLn/p6LG7gr/v8v+52+4Ka93EaOkkIMlkQIJRjySTHolGPRJP/dX/e50EuL0KXF4Zbv81H3B6YBtyw+Zwo2/IDYd79Hc5TTLpg6UlxWyAV1Hg9sroG3Kje8AF+yk/CQVIEjAxx4IF5Rm4bEI2Lq7IRIqZ24KJ6MKOdwxgw6E2fHioHTvqunH6z3BZKWaMz0lGWVYyxmUmozQzGQVpCbAmGpGWaIIlwSB0vYtmiorL5UJSUhJef/113HjjjcHnly9fjt7eXvztb38b9nqn0wmn0xn8c19fH0pKStDY2BjRovLZ8U48+1E1vAogywq8inLGrx6vAtn/Z1lR4PYqcHpluDzyGbssxoJRr4PZKCHBoIfZqINBp4ME3zc/nSRBJ0mQJEDy/6qDFMzvkf2jFl4FXlmBV5Yx4PLCOYpv2HqdhLREIzKSTUhPMiE9yYj0ZBNSE4wwGXQwGiQY9TqY9BIMOh2Meh0Met9zOp0Eo16CXqeDUZKg10vQB5/zvUavk3wlxGhAgsk3hROpnxacHi8GHB7YHG70OzywOU4WGd+vHtgG3cG39wWfd2PAcWYBOZcciwnl2SmYWZSGmSVpmFmUFtOr+okoOnoHXdjd0ItdjT3YXd+LA81951ygGyBJQIpZD5NeD4Ne8n091un8v9fB4PsGAp0ELKrIwr1XjY9oZpvNhuLiYvT29sJqtZ73tUJ/fOvs7ITX60Vubu6w53Nzc3H48OEzXr9mzRr85Cc/OeP54uLiMctIFCmNAHYCeE10ECKiELwD4KEx+m/39/eru6iEatWqVVi5cmXwz7Iso7u7G5mZmaqbiwu0xUiP9tDZ8XpHF693dPF6Rx+v+dhSFAX9/f0oKCi44GuFFpWsrCzo9Xq0tbUNe76trQ15eXlnvN5sNsNsHr7VMi0tbSwjjlpqair/kUcRr3d08XpHF6939PGaj50LjaQEnH+rwhgzmUyYO3cuNmzYEHxOlmVs2LABCxcuFJiMiIiI1ED41M/KlSuxfPlyzJs3D/Pnz8eTTz4Ju92OO++8U3Q0IiIiEkx4UbnlllvQ0dGBhx9+GK2trZg1axbee++9MxbYao3ZbMbq1avPmKqiscHrHV283tHF6x19vObqIfwcFSIiIqJzEbpGhYiIiOh8WFSIiIhItVhUiIiISLVYVIiIiEi1WFRG4dlnn0VpaSkSEhKwYMECbNu27byvf+2111BZWYmEhARMnz4d7777bpSSxoZQrvfvf/97LF68GOnp6UhPT8eSJUsu+P+Hhgv133fAunXrIEnSsPt30YWFer17e3uxYsUK5Ofnw2w2Y+LEifyaEoJQr/eTTz6JSZMmITExEcXFxfjRj34Eh8MRpbRxTqGwrFu3TjGZTMrzzz+vHDhwQPnOd76jpKWlKW1tbWd9/ebNmxW9Xq/88pe/VA4ePKj8+Mc/VoxGo1JVVRXl5NoU6vW+9dZblWeffVbZvXu3cujQIeWOO+5QrFarcuLEiSgn16ZQr3dAbW2tUlhYqCxevFhZtmxZdMLGgFCvt9PpVObNm6csXbpU+fTTT5Xa2lrl448/Vvbs2RPl5NoU6vV+5ZVXFLPZrLzyyitKbW2t8v777yv5+fnKj370oygnj08sKmGaP3++smLFiuCfvV6vUlBQoKxZs+asr7/55puVL33pS8OeW7BggXL33XePac5YEer1Pp3H41EsFovyxz/+cawixpRwrrfH41EWLVqk/OEPf1CWL1/OohKCUK/32rVrlfLycsXlckUrYkwJ9XqvWLFCueqqq4Y9t3LlSuWSSy4Z05zkw6mfMLhcLuzcuRNLliwJPqfT6bBkyRJ8/vnnZ32fzz//fNjrAeCLX/ziOV9PJ4VzvU83ODgIt9uNjIyMsYoZM8K93j/96U+Rk5ODb3/729GIGTPCud5///vfsXDhQqxYsQK5ubmYNm0afv7zn8Pr9UYrtmaFc70XLVqEnTt3BqeHampq8O6772Lp0qVRyRzvhJ9Mq0WdnZ3wer1nnJ6bm5uLw4cPn/V9Wltbz/r61tbWMcsZK8K53qe7//77UVBQcEZZpDOFc70//fRTPPfcc9izZ08UEsaWcK53TU0NPvroI3zjG9/Au+++i+rqatxzzz1wu91YvXp1NGJrVjjX+9Zbb0VnZycuvfRSKIoCj8eD733ve3jwwQejETnucUSFYt5jjz2GdevW4c0330RCQoLoODGnv78ft912G37/+98jKytLdJy4IMsycnJy8Lvf/Q5z587FLbfcgoceegi/+c1vREeLSR9//DF+/vOf47/+67+wa9cuvPHGG3jnnXfwyCOPiI4WFziiEoasrCzo9Xq0tbUNe76trQ15eXlnfZ+8vLyQXk8nhXO9A371q1/hsccew4cffogZM2aMZcyYEer1Pn78OOrq6nD99dcHn5NlGQBgMBhw5MgRVFRUjG1oDQvn33d+fj6MRiP0en3wucmTJ6O1tRUulwsmk2lMM2tZONf73/7t33DbbbfhrrvuAgBMnz4ddrsd3/3ud/HQQw9Bp+PP/GOJVzcMJpMJc+fOxYYNG4LPybKMDRs2YOHChWd9n4ULFw57PQCsX7/+nK+nk8K53gDwy1/+Eo888gjee+89zJs3LxpRY0Ko17uyshJVVVXYs2dP8HHDDTfgyiuvxJ49e1BcXBzN+JoTzr/vSy65BNXV1cFCCABHjx5Ffn4+S8oFhHO9BwcHzygjgZKo8HZ5Y0/0al6tWrdunWI2m5UXX3xROXjwoPLd735XSUtLU1pbWxVFUZTbbrtNeeCBB4Kv37x5s2IwGJRf/epXyqFDh5TVq1dze3IIQr3ejz32mGIymZTXX39daWlpCT76+/tF/RU0JdTrfTru+glNqNe7oaFBsVgsyr333qscOXJEefvtt5WcnBzlZz/7mai/gqaEer1Xr16tWCwW5U9/+pNSU1OjfPDBB0pFRYVy8803i/orxBUWlVF4+umnlZKSEsVkMinz589XtmzZEnzb5ZdfrixfvnzY6//yl78oEydOVEwmkzJ16lTlnXfeiXJibQvleo8bN04BcMZj9erV0Q+uUaH++z4Vi0roQr3en332mbJgwQLFbDYr5eXlyqOPPqp4PJ4op9auUK632+1W/v3f/12pqKhQEhISlOLiYuWee+5Renp6oh88DkmKwnErIiIiUieuUSEiIiLVYlEhIiIi1WJRISIiItViUSEiIiLVYlEhIiIi1WJRISIiItViUSEiIiLVYlEhIiIi1WJRISIiItViUSEiIiLVYlEhIiIi1WJRISIiItX6/y+eAP+0yO2XAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.kdeplot(data=sentence_sim_result, label=\"tst\", fill=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:01:42.070934Z",
     "start_time": "2024-02-26T13:01:31.144241Z"
    }
   },
   "id": "ad8f7505e3731e3c"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value: 0.6424015708602288\n"
     ]
    }
   ],
   "source": [
    "print('mean value:', np.mean(sentence_sim_result))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:04:53.234361Z",
     "start_time": "2024-02-26T13:04:53.085174Z"
    }
   },
   "id": "89fbddb88f798a46"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "st",
   "language": "python",
   "display_name": "ST"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
